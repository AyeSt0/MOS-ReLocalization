import json
import re
import time
from pathlib import Path

# ========== æ–‡ä»¶è·¯å¾„ ==========
DATA_PATH = Path("output/language_dict_namemap_applied.json")
LANG_MAP_PATH = Path("data/language_map.json")
NAMEMAP_PATH = Path("data/name_map.json")
OUTPUT_PATH = Path("output/language_dict_name_fixed.json")
REPORT_PATH = Path("output/name_fix_report.txt")

# ========== åŠ è½½å‡½æ•° ==========
def load_json(path, default=None):
    if default is None:
        default = {}
    if not path.exists():
        return default
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)

def save_json(path, data):
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp = path.with_suffix(path.suffix + ".tmp")
    with tmp.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    tmp.replace(path)

# ========== æ ¸å¿ƒæ›¿æ¢å‡½æ•° ==========
def normalize_chinese_names(text, name_map):
    """
    å°†æ–‡æœ¬ä¸­å‡ºç°çš„ä¸­è‹±ä¿„æ··åˆä¸“åæ›¿æ¢ä¸º name_map ä¸­å®šä¹‰çš„ä¸­æ–‡è¯‘åã€‚
    """
    if not text:
        return text, []

    replaced = []
    fixed = text
    for key, val in sorted(name_map.items(), key=lambda kv: -len(kv[0])):  # é•¿è¯ä¼˜å…ˆ
        # æ¨¡ç³ŠåŒ¹é…ï¼šè‹±æ–‡ã€ä¿„æ–‡åæˆ–å·²æœ‰ä¸­è¯‘å
        variants = set([key, val])
        if key.lower() != key:
            variants.add(key.lower())
        if key.upper() != key:
            variants.add(key.upper())

        for var in variants:
            if not var or var == val:
                continue
            pattern = re.compile(re.escape(var))
            if re.search(pattern, fixed):
                fixed = pattern.sub(val, fixed)
                replaced.append((var, val))
    return fixed, replaced

# ========== ä¸»é€»è¾‘ ==========
def main():
    data = load_json(DATA_PATH)
    lang_map = load_json(LANG_MAP_PATH)
    name_map = load_json(NAMEMAP_PATH)

    total = len(data)
    ru_col = next((int(k) for k, v in lang_map.items() if "Russian" in v), None)
    en_col = next((int(k) for k, v in lang_map.items() if "English" in v), None)
    zh_col = next((int(k) for k, v in lang_map.items() if "Chinese" in v), None)

    if None in (ru_col, en_col, zh_col):
        print("âŒ æœªæ£€æµ‹åˆ°å®Œæ•´çš„ä¸‰è¯­åˆ—ï¼Œè¯·æ£€æŸ¥ language_map.jsonã€‚")
        return

    print(f"âœ… æ•°æ®è½½å…¥æˆåŠŸï¼šå…± {total} æ¡ã€‚ä¿„æ–‡åˆ—={ru_col}ï¼Œè‹±æ–‡åˆ—={en_col}ï¼Œä¸­æ–‡åˆ—={zh_col}")
    print(f"ğŸ“˜ name_map ä¸­æœ‰ {len(name_map)} æ¡ä¸“åæ˜ å°„ã€‚")

    modified = 0
    report_lines = []

    start = time.time()

    for i, (key, row) in enumerate(data.items(), 1):
        if len(row) <= max(ru_col, en_col, zh_col):
            continue
        ru, en, cn = row[ru_col] or "", row[en_col] or "", row[zh_col] or ""
        # è‹¥è¯¥è¡Œçš„ä¿„æ–‡æˆ–è‹±æ–‡åŒ…å«ä»»ä½• name_map é”®ï¼Œåˆ™è§¦å‘ä¿®æ­£
        if any(k in ru or k in en for k in name_map.keys()):
            new_cn, replaced = normalize_chinese_names(cn, name_map)
            if new_cn != cn:
                data[key][zh_col] = new_cn
                modified += 1
                report_lines.append(
                    f"ã€{i}ã€‘å‘ç°ä¿®æ­£ï¼š{replaced}\nåŸæ–‡ï¼š{cn}\nä¿®æ­£ï¼š{new_cn}\n"
                )

        if i % 200 == 0:
            print(f"â³ è¿›åº¦ {i}/{total} | å·²ä¿®æ­£ {modified}")
            save_json(OUTPUT_PATH, data)

    save_json(OUTPUT_PATH, data)
    with open(REPORT_PATH, "w", encoding="utf-8") as f:
        f.write("\n".join(report_lines))

    print(f"\nâœ… ä¿®æ­£å®Œæˆï¼Œå…± {modified} æ¡ã€‚")
    print(f"ğŸ“˜ æŠ¥å‘Šä¿å­˜è‡³: {REPORT_PATH}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {OUTPUT_PATH}")
    print(f"è€—æ—¶: {time.time()-start:.1f}s")

if __name__ == "__main__":
    main()
