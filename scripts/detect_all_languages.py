# ===================================
# è¯­è¨€è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¸¸æˆç‰ˆï¼‰
# æ”¯æŒï¼šè‘¡è¯­æ–¹è¨€ã€ç®€ç¹ä¸­æ–‡åŒºåˆ†ã€æ¸¸æˆUIå‘½åæ˜ å°„
# ===================================

import json
from pathlib import Path
from langdetect import detect, DetectorFactory

# ===== é…ç½® =====
DATA_PATH = Path("data/language_dict.json")
OUTPUT_PATH = Path("output/language_map.json")

# ===== åˆå§‹åŒ– =====
DetectorFactory.seed = 0


# ===== æ–¹è¨€åˆ¤å®š =====
def guess_portuguese_region(samples):
    """åŒºåˆ†è‘¡è„ç‰™è¯­ä¸å·´è¥¿è‘¡è¯­"""
    br_markers = ["vocÃª", "pra", "tÃ¡", "legal", "cara", "aÃ­", "beleza", "obrigado", "garota"]
    pt_markers = ["tu", "fixe", "gajo", "rapariga", "estÃ¡s", "pois", "obrigada", "prenda"]
    br_count = sum(any(m in s.lower() for m in br_markers) for s in samples)
    pt_count = sum(any(m in s.lower() for m in pt_markers) for s in samples)
    if br_count > pt_count:
        return "Brazilian Port."
    elif pt_count > br_count:
        return "Portuguese"
    else:
        return "Portuguese"

# ===== æ¸¸æˆè¯­è¨€æ˜ å°„è¡¨ =====
GAME_LANG_MAP = {
    "RU": "Russian",
    "EN": "English",
    "DE": "German",
    "FR": "French",
    "IT": "Italian",
    "ES": "Spanish",
    "TR": "Turkish",
    "PL": "Polish",
    "CS": "Czech",
    "UK": "Ukrainian",
    "AR": "Arabian",
    "FA": "Persian",
    "HU": "Hungarian",
    "PT": "Portuguese",
    "PT-BR": "Brazilian Port.",
    "ZH-CN": "Chinese (Simplified Chinese)",
    "ZH-TW": "Chinese (Traditional Chinese)",
    "META": "META",
    "UNKNOWN": "Unknown"
}

# ===== æ£€æµ‹å‡½æ•° =====
def detect_language(text):
    try:
        return detect(text)
    except Exception:
        return "UNKNOWN"


# ===== ä¸»æµç¨‹ =====
def detect_all_languages_pro(verbose=True):
    if not DATA_PATH.exists():
        print(f"[âŒ] æ–‡ä»¶ä¸å­˜åœ¨: {DATA_PATH}")
        return

    with open(DATA_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    total = len(data)
    max_cols = max(len(v) for v in data.values())
    print(f"âœ… æ€»æ¡ç›®æ•°: {total}ï¼Œæ£€æµ‹åˆ—æ•°: {max_cols}")

    col_texts = {i: [] for i in range(max_cols)}
    for v in data.values():
        for i, val in enumerate(v):
            if isinstance(val, str) and val.strip():
                col_texts[i].append(val.strip())

    result_map = {}

    for col, texts in col_texts.items():
        if col == 0:
            print(f"\nğŸ§© åˆ— {col:02d}: META (è·³è¿‡è¯­è¨€æ£€æµ‹)")
            result_map[col] = "META"
            continue

        if not texts:
            result_map[col] = "Unknown"
            print(f"\nğŸ§© åˆ— {col:02d}: Unknown (0%) | æ ·æœ¬æ•°: 0")
            continue

        # æŒ‰å­—ç¬¦é•¿åº¦æ’åºï¼Œå–æœ€é•¿çš„200æ¡ç”¨äºæ£€æµ‹
        sorted_texts = sorted(texts, key=len, reverse=True)[:200]
        detected = [detect_language(t).upper() for t in sorted_texts if detect_language(t)]

        if not detected or all(l == "UNKNOWN" for l in detected):
            display_name = "Unknown"
        else:
            main_lang = max(set(detected), key=detected.count)
            display_name = GAME_LANG_MAP.get(main_lang, "Unknown")

            # ç‰¹æ®Šå¤„ç†è‘¡è¯­
            if main_lang == "PT":
                display_name = guess_portuguese_region(sorted_texts)

        # ç™¾åˆ†æ¯” = æœ‰æ•ˆæ ·æœ¬æ•° / æ€»æ¡ç›®æ•°
        pct = (len(texts) / total) * 100

        result_map[col] = display_name
        print(f"\nğŸ§© åˆ— {col:02d}: {display_name} ({pct:.0f}%) | æ ·æœ¬æ•°: {len(texts)}")

    OUTPUT_PATH.parent.mkdir(exist_ok=True)
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        json.dump(result_map, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ£€æµ‹å®Œæˆï¼Œå…± {max_cols} åˆ—ï¼›å”¯ä¸€è¯­è¨€æ•°: {len(set(result_map.values()))}")
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_PATH}")


# ===== ç¨‹åºå…¥å£ =====
if __name__ == "__main__":
    detect_all_languages_pro(verbose=True)