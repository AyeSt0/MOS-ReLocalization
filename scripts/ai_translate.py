import os, json, time, sys, signal, threading, re
from pathlib import Path
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed

# ===== ÁéØÂ¢ÉÂä†ËΩΩ =====
load_dotenv()

# ===== Ë∑ØÂæÑÈÖçÁΩÆ =====
DATA_JSON = Path("data/language_dict.json")
LANG_MAP_JSON = Path("output/language_map.json")
OUTPUT_JSON = Path("output/language_dict_translated.json")
NAME_MAP_JSON = Path("output/name_map.json")

# ===== ËØªÂèñ ENV =====
MODEL_PROVIDER = os.getenv("MODEL_PROVIDER", "chatgpt").lower()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "")
DEEPSEEK_MODEL = os.getenv("DEEPSEEK_MODEL", "deepseek-ai/DeepSeek-R1")
MODEL = os.getenv("MODEL", "gpt-4o-mini")
THREADS = int(os.getenv("THREADS", "5"))
REQUEST_TIMEOUT = int(os.getenv("REQUEST_TIMEOUT", "30"))
BATCH_FLUSH = int(os.getenv("BATCH_FLUSH", "50"))

# ===== Ê®°ÂûãÂÆ¢Êà∑Á´Ø =====
if MODEL_PROVIDER == "chatgpt":
    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)
elif MODEL_PROVIDER == "deepseek":
    import openai
    openai.api_key = DEEPSEEK_API_KEY
    openai.base_url = f"{DEEPSEEK_BASE_URL}/v1"
    client = openai
else:
    raise RuntimeError("‚ùå MODEL_PROVIDER ÂøÖÈ°ª‰∏∫ chatgpt Êàñ deepseek")

# ===== Âü∫Á°ÄÂáΩÊï∞ =====
def load_json(path, default):
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return default

def save_json(path, data):
    path.parent.mkdir(exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def ensure_column_capacity(arr: list, n: int):
    while len(arr) < n:
        arr.append("")

# ===== ÂÖ®Â±ÄÈÄÄÂá∫Èí©Â≠ê =====
def graceful_exit(signum, frame):
    print("\n‚ö†Ô∏è ÊçïËé∑‰∏≠Êñ≠‰ø°Âè∑ÔºåÂÆâÂÖ®ËêΩÁõòÂêéÈÄÄÂá∫‚Ä¶‚Ä¶")
    save_json(OUTPUT_JSON, data)
    sys.exit(0)

signal.signal(signal.SIGINT, graceful_exit)
signal.signal(signal.SIGTERM, graceful_exit)

# ===== Prompt Ê®°Êùø =====
def build_prompt(text, target_lang):
    return f"""
You are a professional game localization translator.
Translate the following English text into natural, immersive Chinese ({target_lang}),
making it appropriate for a visual novel game.
Keep dialogue fluent and emotionally expressive; preserve tone and intent.
Do not omit or summarize details.
Text:
{text}
""".strip()

# ===== ÁøªËØëÊé•Âè£ =====
def translate_once(text, target_lang):
    if not text.strip():
        return ""

    for attempt in range(5):
        try:
            if MODEL_PROVIDER == "chatgpt":
                resp = client.chat.completions.create(
                    model=MODEL,
                    messages=[
                        {"role": "system", "content": "You are a professional translator."},
                        {"role": "user", "content": build_prompt(text, target_lang)},
                    ],
                    timeout=REQUEST_TIMEOUT,
                )
                return (resp.choices[0].message.content or "").strip()

            else:  # DeepSeek
                resp = client.ChatCompletion.create(
                    model=DEEPSEEK_MODEL,
                    messages=[
                        {"role": "system", "content": "You are a professional translator."},
                        {"role": "user", "content": build_prompt(text, target_lang)},
                    ],
                    timeout=REQUEST_TIMEOUT,
                )
                return (resp.choices[0].message["content"] or "").strip()
        except Exception as e:
            wait = 2 * (attempt + 1)
            print(f"‚è≥ ÈáçËØï {attempt+1}/5Ôºö{type(e).__name__}Ôºå{wait}s ÂêéÂÜçËØï...")
            time.sleep(wait)

    print(f"‚ùå ÁøªËØëÂ§±Ë¥•ÔºàÂ∑≤ËææÈáçËØï‰∏äÈôêÔºâÔºåËøîÂõûÁ©∫Ôºö{text[:40]}")
    return ""

# ===== ‰∏ìÊúâÂêçËØçÁªü‰∏ÄÊò†Â∞Ñ =====
def apply_name_map(text, name_map):
    for k, v in name_map.items():
        text = re.sub(rf"\b{k}\b", v, text)
    return text

def update_name_map(original, translated, name_map):
    english_tokens = re.findall(r'\b[A-Z][a-zA-Z]+\b', original)
    for token in english_tokens:
        if token not in name_map and token.lower() not in ["the", "a", "an"]:
            if translated and not re.search(r"[A-Za-z]", translated):
                name_map[token] = translated
                print(f"üß© Êñ∞Â¢û‰∏ìÊúâÂêçËØçÊò†Â∞ÑÔºö{token} ‚Üí {translated}")
                save_json(NAME_MAP_JSON, name_map)
    return name_map

# ===== Êñ∞Â¢ûËØ≠Ë®ÄÂàó =====
def add_new_language_column(data, lang_map):
    max_col = max(int(k) for k in lang_map.keys())
    print(f"\nüìä ÂΩìÂâçÊúÄÂ§ßÂàóÂè∑‰∏∫ {max_col}„ÄÇ")
    choice = input("ÊòØÂê¶Ë¶ÅÊñ∞Â¢ûËØ≠Ë®ÄÂàóÔºü(y/n)Ôºö").strip().lower()
    if choice != "y":
        return lang_map, None

    new_col_input = input(f"ËØ∑ËæìÂÖ•Ë¶ÅÊèíÂÖ•ÁöÑÊñ∞ÂàóÂè∑ÔºàÈªòËÆ§ {max_col+1}ÔºâÔºö").strip()
    new_col = int(new_col_input) if new_col_input else max_col + 1

    for i in range(max_col + 1, new_col):
        lang_map[str(i)] = "Unknown"

    new_lang_name = input("ËØ∑ËæìÂÖ•Êñ∞ËØ≠Ë®ÄÂêçÁß∞Ôºà‰æãÂ¶ÇÔºöJapanese„ÄÅKoreanÔºâÔºö").strip() or "Unknown"
    lang_map[str(new_col)] = new_lang_name

    for v in data.values():
        ensure_column_capacity(v, new_col + 1)
        v[new_col] = ""

    save_json(DATA_JSON, data)
    save_json(LANG_MAP_JSON, lang_map)
    print(f"‚úÖ Â∑≤Êñ∞Â¢ûÂàó {new_col}Ôºö{new_lang_name}")
    return lang_map, new_col

# ===== ÂèØÁøªËØëÂàóÈÄâÊã© =====
def pick_target_column(lang_map, data):
    english_col = None
    total = len(data)
    candidates, unknowns = [], []

    for k, v in sorted(lang_map.items(), key=lambda kv: int(kv[0])):
        if v == "META":
            continue
        count = sum(1 for row in data.values() if int(k) < len(row) and row[int(k)].strip())
        pct = (count / total) * 100
        if v == "English":
            english_col = int(k)
        if v == "Unknown":
            unknowns.append((int(k), v, pct))
        else:
            candidates.append((int(k), v, pct))

    print("\nÂèØÁøªËØëÂàóÂ¶Ç‰∏ãÔºö")
    for c in candidates:
        print(f"  - Âàó {c[0]}: {c[1]} ({c[2]:.1f}%)")
    if unknowns:
        print("\nüü° Ê£ÄÊµãÂà∞ Unknown ÂàóÔºåÂèØÈÄâÊã©ÂàõÂª∫Êñ∞ËØ≠Ë®ÄÁøªËØëÔºö")
        for c in unknowns:
            print(f"  - Âàó {c[0]}: {c[1]} ({c[2]:.1f}%)")

    tgt_col_input = input("\nüëâ ËØ∑ËæìÂÖ•Ë¶ÅËøõË°åÊú¨Âú∞ÂåñÁøªËØëÁöÑÁõÆÊ†áÂàóÂè∑ÔºàÊàñÂõûËΩ¶Êñ∞Â¢ûËØ≠Ë®ÄÔºâÔºö").strip()
    if not tgt_col_input:
        lang_map, new_col = add_new_language_column(data, lang_map)
        if new_col is None:
            raise RuntimeError("Êú™ÈÄâÊã©ÁøªËØëÁõÆÊ†áÂàó„ÄÇ")
        return english_col, new_col, lang_map
    return english_col, int(tgt_col_input), lang_map

# ===== ÁøªËØëÊâßË°å =====
def translate_all(data, english_col, target_col, target_lang, name_map):
    total = len(data)
    idx_lock = threading.Lock()
    counter = {"count": 0}

    def worker(k):
        with idx_lock:
            idx = counter["count"] + 1
            counter["count"] += 1

        arr = data[k]
        ensure_column_capacity(arr, target_col + 1)
        src = arr[english_col].strip()
        if not src:
            return
        src_with_replacement = apply_name_map(src, name_map)
        result = translate_once(src_with_replacement, target_lang)
        name_map = update_name_map(src, result, name_map)
        with idx_lock:
            arr[target_col] = result
            if idx % 10 == 0:
                save_json(OUTPUT_JSON, data)
            print(f"üîÑ Ê≠£Âú®ÁøªËØëÁ¨¨ {idx}/{total} Êù°...\n  ÂéüÊñá: {src}\n  ËØëÊñá: {result}\n")

    with ThreadPoolExecutor(max_workers=THREADS) as exe:
        futures = [exe.submit(worker, k) for k in data.keys()]
        for _ in as_completed(futures):
            pass

# ===== ‰∏ªÁ®ãÂ∫èÂÖ•Âè£ =====
def main():
    global data
    data = load_json(DATA_JSON, {})
    lang_map = load_json(LANG_MAP_JSON, {})
    name_map = load_json(NAME_MAP_JSON, {})

    print(f"‚úÖ Âä†ËΩΩÂÆåÊàêÔºåÂÖ± {len(data)} Êù°ËÆ∞ÂΩï„ÄÇ")
    english_col, target_col, lang_map = pick_target_column(lang_map, data)

    print(f"\nüåç Â∞Ü‰ªéÂàó {english_col}ÔºàEnglishÔºâ ÁøªËØëÂà∞Âàó {target_col}Ôºà{lang_map[str(target_col)]}Ôºâ")
    mode = input("\nÈÄâÊã©Ê®°ÂºèÔºö1=ÁªßÁª≠ÁøªËØëÔºàË°•Á©∫Ôºâ / 2=Âº∫Âà∂ÁøªËØëÔºàÊ∏ÖÁ©∫ÈáçÊù•ÔºâÔºö").strip()
    if mode == "2":
        confirm = input("‚ö†Ô∏è Á°ÆËÆ§Ë¶ÅÊ∏ÖÁ©∫ËØ•ÂàóÁöÑÊâÄÊúâÁøªËØëÂêóÔºü(y/n)Ôºö").strip().lower()
        if confirm == "y":
            for arr in data.values():
                ensure_column_capacity(arr, target_col + 1)
                arr[target_col] = ""
            print("üßπ Â∑≤Ê∏ÖÁ©∫ÁõÆÊ†áÂàó„ÄÇ")

    not_done = {k: v for k, v in data.items() if len(v) <= target_col or not v[target_col].strip()}
    print(f"üì¶ ÂæÖÁøªËØë: {len(not_done)} Êù°„ÄÇ")

    translate_all(data, english_col, target_col, lang_map[str(target_col)], name_map)
    save_json(OUTPUT_JSON, data)
    print(f"\nüéâ ÁøªËØëÂÆåÊàêÔºåÁªìÊûúÂ∑≤‰øùÂ≠òËá≥ {OUTPUT_JSON}")
    print(f"üìò ‰∏ìÊúâÂêçËØçÊò†Â∞ÑË°®Â∑≤Êõ¥Êñ∞ -> {NAME_MAP_JSON}")

if __name__ == "__main__":
    main()
