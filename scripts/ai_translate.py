# scripts/ai_translate.py
import os, sys, json, time, signal, re, threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv

# ========== åˆå§‹åŒ–ä¸è·¯å¾„ ==========
load_dotenv()

DATA_PATH        = Path("data/language_dict.json")
LANG_MAP_PATH    = Path("data/language_map.json")
NAME_MAP_PATH    = Path("data/name_map.json")
OUTPUT_PATH      = Path("output/language_dict_translated.json")

THREADS          = int(os.getenv("THREADS", "5"))
BATCH_FLUSH      = int(os.getenv("BATCH_FLUSH", "50"))
REQUEST_TIMEOUT  = int(os.getenv("REQUEST_TIMEOUT", "30"))

DEFAULT_PROVIDER = os.getenv("MODEL_PROVIDER", "chatgpt").strip().lower()

OPENAI_API_KEY   = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL     = os.getenv("MODEL", "gpt-4o-mini").strip()

DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "").strip()
DEEPSEEK_BASEURL = os.getenv("DEEPSEEK_BASE_URL", "https://api.siliconflow.cn").strip()
DEEPSEEK_MODEL   = os.getenv("DEEPSEEK_MODEL", "deepseek-ai/DeepSeek-R1").strip()

stop_requested = False
NAME_LOCK = threading.Lock()

# ========== ä¿¡å·å¤„ç† ==========
def handle_signal(signum, frame):
    global stop_requested
    stop_requested = True
    print("\nâš ï¸ æ•è·åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨è½ç›˜å¹¶é€€å‡ºâ€¦â€¦")

signal.signal(signal.SIGINT, handle_signal)
signal.signal(signal.SIGTERM, handle_signal)

# ========== å·¥å…·å‡½æ•° ==========
def load_json(path: Path, default=None):
    if default is None: default = {}
    if not path.exists(): return default
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)

def save_json(path: Path, data):
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp = path.with_suffix(path.suffix + ".tmp")
    with tmp.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    tmp.replace(path)

def ensure_row_len(row: list, length: int):
    if len(row) <= length:
        row.extend([""] * (length - len(row) + 1))

# ========== æ¨¡å‹å®¢æˆ·ç«¯ ==========
def choose_provider():
    print("\nè¯·é€‰æ‹©ç¿»è¯‘å¼•æ“ï¼š")
    print("  1) ChatGPT (OpenAI)")
    print("  2) DeepSeek (OpenAIå…¼å®¹)")
    choice = input(f"ğŸ‘‰ è¾“å…¥ 1 æˆ– 2 (é»˜è®¤: {DEFAULT_PROVIDER})ï¼š").strip()
    provider = "deepseek" if (choice == "2" or (not choice and DEFAULT_PROVIDER == "deepseek")) else "chatgpt"
    print(f"ğŸ§  ä½¿ç”¨ {provider.upper()} æ¨¡å‹å¼•æ“\n")
    return provider

def build_client(provider: str):
    from openai import OpenAI
    if provider == "deepseek":
        return OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASEURL), DEEPSEEK_MODEL
    return OpenAI(api_key=OPENAI_API_KEY), OPENAI_MODEL

# ========== Prompt ==========
def build_prompt(text, target_lang):
    return f"""
You are a professional Chinese localizer specializing in adult visual novels.
Translate the following Russian line into fluent, natural Chinese ({target_lang})
for the game "MILFs of Sunville".

Guidelines:
- Preserve sensuality, emotion, and tone.
- Keep idiomatic phrasing natural for modern Chinese dialogue.
- Only output the translation itself (no explanations, no quotes).
- Retain variables like {{mcname}}, [var], <tag>.

Text:
{text}
""".strip()

def build_name_prompt(names: list):
    joined = ", ".join(names)
    return f"""
Translate the following Russian or English person names into natural, culturally consistent Chinese names.
Output valid JSON only, e.g. {{"åŸå": "è¯‘å", ...}}, without extra text.

Names: {joined}
""".strip()

def clean_output(s):
    if not s: return ""
    s = s.strip().strip("`").strip()
    lines = [ln.strip() for ln in s.splitlines() if ln.strip()]
    return lines[0] if lines else ""

# ========== ç¿»è¯‘å™¨ ==========
class Translator:
    def __init__(self, provider):
        self.provider = provider
        self.client, self.model = build_client(provider)
        from openai import APIError, RateLimitError, APITimeoutError, BadRequestError
        self.APIError, self.RateLimitError, self.APITimeoutError, self.BadRequestError = APIError, RateLimitError, APITimeoutError, BadRequestError

    def chat(self, sys_prompt, user_prompt):
        resp = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": user_prompt}],
            temperature=0.5, timeout=REQUEST_TIMEOUT
        )
        return resp.choices[0].message.content or ""

    def translate_name_batch(self, names):
        prompt = build_name_prompt(names)
        try:
            out = self.chat("You are a precise transliteration assistant.", prompt)
            return json.loads(out)
        except Exception:
            try:
                cleaned = re.search(r"\{.*\}", out, re.S)
                return json.loads(cleaned.group(0)) if cleaned else {}
            except Exception:
                return {}

# ========== ä¸“åçƒ­è¯è®­ç»ƒ ==========
def pretrain_name_map(data, lang_map, translator):
    print("ğŸ§  å¯åŠ¨ä¸“åçƒ­è¯è®­ç»ƒæ¨¡å¼...\n")
    src_col = next((int(k) for k, v in lang_map.items() if "Russian" in v), None)
    if src_col is None:
        raise RuntimeError("language_map.json æœªæ£€æµ‹åˆ° Russian åˆ—ã€‚")

    name_map = load_json(NAME_MAP_PATH, default={})
    words = set()

    for arr in data.values():
        if len(arr) <= src_col: continue
        text = arr[src_col]
        if not text or not isinstance(text, str): continue
        tokens = re.findall(r"[Ğ-Ğ¯ĞA-Z][Ğ°-ÑÑ‘a-z]{2,}", text)
        for t in tokens:
            if len(t) <= 2 or t.lower() in ("Ğ¾Ğ½Ğ°","ÑÑ‚Ğ¾","Ğ¼Ğ¾Ğ¹","Ğ¼Ğ°Ğ¼Ğ°"): continue
            words.add(t)

    unknown = [w for w in sorted(words) if w not in name_map]
    print(f"ğŸ“Š å‘ç° {len(unknown)} ä¸ªæ½œåœ¨ä¸“åã€‚\n")

    new_map = {}
    batch_size = 20
    for i in range(0, len(unknown), batch_size):
        batch = unknown[i:i+batch_size]
        result = translator.translate_name_batch(batch)
        if isinstance(result, dict):
            new_map.update(result)
            print(f"âœ… å·²å¤„ç† {min(i+batch_size, len(unknown))}/{len(unknown)} ä¸“å")
        save_json(NAME_MAP_PATH, {**name_map, **new_map})

    print("\nğŸ‰ ä¸“åçƒ­è¯è®­ç»ƒå®Œæˆï¼Œç»“æœå·²å†™å…¥ -> output/name_map.json")

# ========== ä¸»æµç¨‹ ==========
def main():
    provider = choose_provider()
    translator = Translator(provider)

    data = load_json(DATA_PATH)
    lang_map = load_json(LANG_MAP_PATH)
    name_map = load_json(NAME_MAP_PATH)

    choice = input("æ˜¯å¦è¿›è¡Œä¸“åçƒ­è¯è®­ç»ƒï¼Ÿ(y/n)ï¼š").strip().lower()
    if choice == "y":
        pretrain_name_map(data, lang_map, translator)
        print("âœ… ä¸“åçƒ­è¯è®­ç»ƒå®Œæˆï¼Œå¯é‡æ–°è¿è¡Œè¿›è¡Œç¿»è¯‘ã€‚")
        return

    total = len(data)
    src_col = next((int(k) for k, v in lang_map.items() if "Russian" in v), None)
    if src_col is None:
        print("âŒ æœªæ£€æµ‹åˆ° Russian åˆ—ã€‚")
        return

    # é€‰æ‹©ç›®æ ‡åˆ—
    print("\nå¯ç¿»è¯‘åˆ—å¦‚ä¸‹ï¼š")
    for k, v in lang_map.items():
        if v == "META": continue
        print(f"  - åˆ— {k}: {v}")
    tgt_col = int(input("\nğŸ‘‰ è¯·è¾“å…¥ç›®æ ‡åˆ—å·ï¼š").strip() or 5)
    target_lang = lang_map.get(str(tgt_col), "Chinese (Simplified Chinese)")

    # æ¨¡å¼é€‰æ‹©
    mode = input("é€‰æ‹©æ¨¡å¼ï¼š1=ç»§ç»­ç¿»è¯‘ / 2=å¼ºåˆ¶ç¿»è¯‘ï¼š").strip()
    if mode == "2":
        confirm = input("âš ï¸ ç¡®è®¤æ¸…ç©ºç›®æ ‡åˆ—æ‰€æœ‰ç¿»è¯‘å—ï¼Ÿ(y/n)ï¼š").strip().lower()
        if confirm == "y":
            for row in data.values():
                ensure_row_len(row, tgt_col)
                row[tgt_col] = ""
            save_json(DATA_PATH, data)
            print("ğŸ§¹ å·²æ¸…ç©ºç›®æ ‡åˆ—ã€‚")

    # ç¿»è¯‘ä»»åŠ¡
    todo = []
    for key, row in data.items():
        ensure_row_len(row, max(src_col, tgt_col))
        src = (row[src_col] or "").strip()
        tgt = (row[tgt_col] or "").strip()
        if src and not tgt:
            todo.append((key, src))
    print(f"\nğŸ“¦ å¾…ç¿»è¯‘ {len(todo)} æ¡ã€‚\n")

    processed = 0
    last_flush = 0

    def worker(key, text):
        pre = text
        out = translator.chat("You are a professional translator.", build_prompt(pre, target_lang))
        return key, text, clean_output(out)

    with ThreadPoolExecutor(max_workers=THREADS) as ex:
        futures = [ex.submit(worker, key, src) for key, src in todo]
        for fut in as_completed(futures):
            if stop_requested: break
            try:
                key, src, out = fut.result()
            except Exception as e:
                print(f"âŒ æ‰§è¡Œé”™è¯¯ï¼š{e}")
                continue
            data[key][tgt_col] = out
            processed += 1
            print(f"ğŸ”„ æ­£åœ¨ç¿»è¯‘ç¬¬ {processed}/{len(todo)} æ¡...\n  åŸæ–‡: {src}\n  è¯‘æ–‡: {out}\n")

            if processed - last_flush >= BATCH_FLUSH:
                save_json(OUTPUT_PATH, data)
                last_flush = processed
                print(f"ğŸ’¾ è‡ªåŠ¨ä¿å­˜è¿›åº¦ -> {OUTPUT_PATH}")

    save_json(OUTPUT_PATH, data)
    print(f"\nğŸ‰ ç¿»è¯‘å®Œæˆ -> {OUTPUT_PATH}")

if __name__ == "__main__":
    main()
