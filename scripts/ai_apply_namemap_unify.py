import os
import json
import time
import asyncio
import hashlib
from pathlib import Path
from dotenv import load_dotenv
from contextlib import asynccontextmanager
from typing import Dict

# ================== ç¯å¢ƒé…ç½® ==================
load_dotenv()

DATA_PATH = Path("output/language_dict_mcsurname_fixed.json")
LANG_MAP_PATH = Path("data/language_map.json")
NAME_MAP_PATH = Path("data/name_map.json")
OUTPUT_PATH = Path("output/language_dict_namemap_applied.json")
CACHE_PATH = Path("cache/namemap_apply_cache.json")

# ================== æ¨¡å‹é…ç½® ==================
DEFAULT_PROVIDER = os.getenv("MODEL_PROVIDER", "").strip().lower()
OPENAI_API_KEY   = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL     = os.getenv("MODEL", "gpt-4o-mini")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
DEEPSEEK_BASEURL = os.getenv("DEEPSEEK_BASE_URL", "https://api.siliconflow.cn")
DEEPSEEK_MODEL   = os.getenv("DEEPSEEK_MODEL", "deepseek-ai/DeepSeek-R1")

# ================== æ€§èƒ½å‚æ•° ==================
ASYNC_CONCURRENCY = 60
BATCH_FLUSH = 500
PRINT_EVERY = 50
REQUEST_TIMEOUT = 40
SAVE_LOCK = asyncio.Lock()

# ================== å·¥å…·å‡½æ•° ==================
def load_json(path: Path, default=None):
    if default is None:
        default = {}
    if not path.exists():
        return default
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)

async def async_save_json(path: Path, data):
    """å¼‚æ­¥å®‰å…¨å†™å…¥"""
    async with SAVE_LOCK:
        path.parent.mkdir(parents=True, exist_ok=True)
        tmp = path.with_suffix(path.suffix + ".tmp")
        try:
            with tmp.open("w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            if path.exists():
                os.remove(path)
            os.replace(tmp, path)
        except Exception as e:
            print(f"âš ï¸ å†™å…¥ {path.name} å¤±è´¥ï¼š{e}")

def sha1(s: str) -> str:
    return hashlib.sha1(s.encode("utf-8")).hexdigest()

def pick_col_by_lang(lang_map: Dict[str, str], label_contains: str) -> int:
    for k, v in lang_map.items():
        if v and label_contains.lower() in v.lower():
            return int(k)
    return -1

# ================== æ¨¡å‹å®¢æˆ·ç«¯ ==================
@asynccontextmanager
async def build_async_client(provider: str):
    from openai import AsyncOpenAI
    if provider == "deepseek":
        client = AsyncOpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASEURL)
        model = DEEPSEEK_MODEL
        yield client, model
        await client.close()
    else:
        client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        model = OPENAI_MODEL
        yield client, model
        await client.close()

def choose_provider():
    print("\nè¯·é€‰æ‹©å¼•æ“ï¼ˆ1=ChatGPTï¼Œ2=DeepSeekï¼‰ï¼š", end="")
    choice = input().strip()
    if choice == "2" or (not choice and DEFAULT_PROVIDER == "deepseek"):
        provider = "deepseek"
    else:
        provider = "chatgpt"
    print(f"ğŸ§  ä½¿ç”¨ {provider.upper()} æ¨¡å‹å¼•æ“")
    return provider

# ================== Prompt ==================
def build_prompt(russian: str, english: str, chinese: str, name_map: Dict[str, str]) -> str:
    name_list = ", ".join([f"{k}:{v}" for k, v in name_map.items()])
    return f"""
ä½ æ˜¯ä¸€åèµ„æ·±çš„æœ¬åœ°åŒ–ç¼–è¾‘ï¼Œè´Ÿè´£æˆäººè§†è§‰å°è¯´çš„ä¸­æ–‡è¯‘æ–‡ä¸€è‡´æ€§ä¿®æ­£ã€‚
è¯·ä½¿ç”¨æ˜ å°„è¡¨ä¸­çš„ä¸“åï¼Œç»Ÿä¸€ä¸‹åˆ—æ–‡æœ¬çš„è¯‘åï¼Œä¿æŒè‡ªç„¶ã€å‰åä¸€è‡´ã€ç¬¦åˆä¸­æ–‡è¯­å¢ƒã€‚

---
æ˜ å°„è¡¨ï¼ˆèŠ‚é€‰ï¼‰ï¼š
{name_list[:4000]}

ä¿„æ–‡åŸå¥ï¼š{russian}
è‹±æ–‡åŸå¥ï¼š{english}
å½“å‰è¯‘æ–‡ï¼š{chinese}
---

è§„åˆ™ï¼š
1. è¾“å‡ºä»…ä¸ºä¿®æ­£åçš„ä¸­æ–‡å¥å­ã€‚
2. ä¸æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡ç‚¹ã€‚
3. è‹¥æ— éœ€ä¿®æ”¹ï¼ŒåŸæ ·è¾“å‡ºã€‚
4. ä¼˜åŒ–äººåã€åœ°åã€æ ¡åç­‰ä¸“åè¯‘æ³•ã€‚
""".strip()

def clean_model_output(s: str) -> str:
    if not s:
        return ""
    lines = [ln.strip() for ln in s.strip().splitlines() if ln.strip()]
    return lines[0] if lines else ""

# ================== å®æ—¶è¿›åº¦æ¡ ==================
def progress_bar(current: int, total: int, start_time: float):
    bar_len = 30
    filled_len = int(bar_len * current / total)
    bar = "â–ˆ" * filled_len + "-" * (bar_len - filled_len)
    elapsed = time.monotonic() - start_time
    speed = current / elapsed if elapsed > 0 else 0
    remaining = (total - current) / speed if speed > 0 else 0
    eta = time.strftime("%H:%M:%S", time.gmtime(remaining))
    print(f"\râ³ [{bar}] {current}/{total} | ETA: {eta} | Speed: {speed:.1f}/s", end="", flush=True)

# ================== ä¸»é€»è¾‘ ==================
async def main_async():
    provider = choose_provider()

    # åŠ è½½æ–‡ä»¶
    data = load_json(DATA_PATH)
    lang_map = load_json(LANG_MAP_PATH)
    name_map = load_json(NAME_MAP_PATH, default={})
    cache = load_json(CACHE_PATH, default={})
    total = len(data)

    ru_col = pick_col_by_lang(lang_map, "Russian")
    en_col = pick_col_by_lang(lang_map, "English")
    zh_col = pick_col_by_lang(lang_map, "Chinese")

    if min(ru_col, en_col, zh_col) < 0:
        print("âŒ language_map.json æœªæ£€æµ‹åˆ°å®Œæ•´çš„ Russian / English / Chinese åˆ—")
        return

    print(f"âœ… æ•°æ®è½½å…¥æˆåŠŸï¼šå…± {total} æ¡ã€‚ä¿„æ–‡åˆ—={ru_col}ï¼Œè‹±æ–‡åˆ—={en_col}ï¼Œä¸­æ–‡åˆ—={zh_col}")
    print(f"ğŸ“˜ name_map ä¸­æœ‰ {len(name_map)} æ¡ä¸“åæ˜ å°„ã€‚")

    # ä»…å–å«ä¸“åçš„è¡Œ
    keywords = list(name_map.keys())
    print(f"ğŸ” æ£€æµ‹ä¸“åï¼šå…± {len(keywords)} ä¸ª")

    tasks = []
    for i, (key, row) in enumerate(data.items(), 1):
        if len(row) <= max(ru_col, en_col, zh_col):
            continue
        ru = str(row[ru_col] or "")
        en = str(row[en_col] or "")
        cn = str(row[zh_col] or "")
        if not cn.strip():
            continue
        if any(k in ru or k in en for k in keywords):
            tasks.append((i, key, ru, en, cn))

    print(f"ğŸ“¦ å¾…ä¿®æ­£å¥å­æ•°ï¼š{len(tasks)}ï¼ˆä»…æ£€æµ‹è‹±æ–‡/ä¿„æ–‡å«ä¸“åè¡Œï¼‰")

    async with build_async_client(provider) as (client, model):
        sem = asyncio.Semaphore(ASYNC_CONCURRENCY)
        modified = 0
        last_flush_time = time.monotonic()
        start_time = time.monotonic()

        async def worker(i: int, key: str, ru: str, en: str, cn: str):
            nonlocal modified, last_flush_time
            async with sem:
                ck = sha1(f"{ru}|{en}|{cn}")
                if ck in cache:
                    new_cn = cache[ck]
                else:
                    prompt = build_prompt(ru, en, cn, name_map)
                    try:
                        resp = await client.chat.completions.create(
                            model=model,
                            messages=[
                                {"role": "system", "content": "You are a localization editor. Output corrected Chinese only."},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=0.4,
                            timeout=REQUEST_TIMEOUT
                        )
                        new_cn = clean_model_output(resp.choices[0].message.content)
                        cache[ck] = new_cn
                    except Exception as e:
                        print(f"\nâš ï¸ ç¬¬{i}æ¡å‡ºé”™ï¼š{type(e).__name__} â†’ {e}")
                        new_cn = cn

                if new_cn and new_cn != cn:
                    modified += 1
                    data[key][zh_col] = new_cn
                    print(f"\nğŸ”§ ä¿®æ­£ {i}/{len(tasks)}ï¼š{cn[:40]} â†’ {new_cn[:40]}")

                progress_bar(i, len(tasks), start_time)

                if i % BATCH_FLUSH == 0 or (time.monotonic() - last_flush_time > 90):
                    await async_save_json(OUTPUT_PATH, data)
                    await async_save_json(CACHE_PATH, cache)
                    last_flush_time = time.monotonic()
                    print(f"\nğŸ’¾ è‡ªåŠ¨ä¿å­˜è¿›åº¦ ({i}/{len(tasks)})")

        # å¼‚æ­¥æ‰§è¡Œ
        await asyncio.gather(*[worker(*task) for task in tasks])

        # æœ€ç»ˆä¿å­˜
        await async_save_json(OUTPUT_PATH, data)
        await async_save_json(CACHE_PATH, cache)

    print(f"\nğŸ‰ ä¿®æ­£å®Œæˆï¼Œå…±ä¿®æ”¹ {modified} æ¡ã€‚ç»“æœå·²ä¿å­˜è‡³ {OUTPUT_PATH}")

def main():
    asyncio.run(main_async())

if __name__ == "__main__":
    main()
